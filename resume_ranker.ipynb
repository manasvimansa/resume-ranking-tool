{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d52080-1c43-49cf-9e26-79927c6ed8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load skills from file\n",
    "with open(\"skills.txt\") as f:\n",
    "    skill_list = [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "# Preprocess skills to allow multi-word matching\n",
    "skill_set = set(skill_list)\n",
    "\n",
    "def extract_skills(text):\n",
    "    doc = nlp(text.lower())\n",
    "    extracted_skills = set()\n",
    "\n",
    "    # Extract noun chunks for multi-word skills\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.strip().lower()\n",
    "        if chunk_text in skill_set:\n",
    "            extracted_skills.add(chunk_text)\n",
    "\n",
    "    # Also check individual tokens (for single word skills)\n",
    "    for token in doc:\n",
    "        if token.text in skill_set:\n",
    "            extracted_skills.add(token.text)\n",
    "    \n",
    "    return extracted_skills\n",
    "\n",
    "# Example usage (for testing)\n",
    "resume_text = \"\"\"Experienced Python developer with Flask, React, MongoDB, and NLP tools like spaCy and machine learning.\"\"\"\n",
    "skills_found = extract_skills(resume_text)\n",
    "print(\"Extracted Skills:\", skills_found)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e59e597-0622-4baa-b978-c44d4e5e75fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\hp\\onedrive\\desktop\\python\\spacy-env\\lib\\site-packages (1.26.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb5732-24a5-4d7d-939e-05f0ac263352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load skills from file\n",
    "with open(\"skills.txt\") as f:\n",
    "    skill_list = [line.strip().lower() for line in f.readlines()]\n",
    "skill_set = set(skill_list)\n",
    "\n",
    "# Skill extraction function\n",
    "def extract_skills(text):\n",
    "    doc = nlp(text.lower())\n",
    "    extracted_skills = set()\n",
    "\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.strip().lower()\n",
    "        if chunk_text in skill_set:\n",
    "            extracted_skills.add(chunk_text)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in skill_set:\n",
    "            extracted_skills.add(token.text)\n",
    "    \n",
    "    return extracted_skills\n",
    "\n",
    "# PDF resume text extraction\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Main script\n",
    "resume_path = input(\"Enter path to resume PDF: \")\n",
    "if os.path.exists(resume_path):\n",
    "    resume_text = extract_text_from_pdf(resume_path)\n",
    "    print(\"\\n--- Resume Text Preview ---\\n\")\n",
    "    print(resume_text[:1000])  # Preview first 1000 characters\n",
    "\n",
    "    # Extract and print skills\n",
    "    skills_found = extract_skills(resume_text)\n",
    "    print(\"\\n--- Extracted Skills ---\\n\")\n",
    "    print(skills_found)\n",
    "else:\n",
    "    print(\"File not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c656b02-c494-4f06-992d-e09654e4665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(resume_text)\n",
    "skills = [token.text for token in doc if token.pos_ in (\"NOUN\", \"PROPN\") and not token.is_stop]\n",
    "print(set(skills))  # Using set to remove duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4de726-1fab-46d3-91de-0c80e13f6264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, \"->\", ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e7dbe-9825-44ea-9f54-04979ecb02ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "\n",
    "def summarize_text(text, n=3):\n",
    "    doc = nlp(text)\n",
    "    word_freq = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in STOP_WORDS and word.text.lower() not in punctuation:\n",
    "            word_freq[word.text.lower()] = word_freq.get(word.text.lower(), 0) + 1\n",
    "\n",
    "    sentence_strength = {}\n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_freq:\n",
    "                sentence_strength[sent] = sentence_strength.get(sent, 0) + word_freq[word.text.lower()]\n",
    "\n",
    "    summary = nlargest(n, sentence_strength, key=sentence_strength.get)\n",
    "    return ' '.join([str(s) for s in summary])\n",
    "\n",
    "print(summarize_text(resume_text, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb0e6e4f-11c0-4837-b131-c87f415f67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "Looking for a Python developer with knowledge in Flask, React, MongoDB, and NLP tools like spaCy.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1ec41-401f-4eed-9b1c-be487b05728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords from text\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    return set(\n",
    "        token.text.lower()\n",
    "        for token in doc\n",
    "        if token.pos_ in (\"NOUN\", \"PROPN\") and not token.is_stop and token.is_alpha\n",
    "    )\n",
    "\n",
    "# Extract keywords from both job description and resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922759c-61f1-4e70-8bc6-3bf1c5bbb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords from text\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    return set(\n",
    "        token.text.lower()\n",
    "        for token in doc\n",
    "        if token.pos_ in (\"NOUN\", \"PROPN\") and not token.is_stop and token.is_alpha\n",
    "    )\n",
    "\n",
    "# Extract keywords from both job description and resume\n",
    "jd_skills = extract_skills(job_description)\n",
    "resume_skills = extract_skills(resume_text)\n",
    "\n",
    "# Calculate matched skills\n",
    "matched_skills = jd_skills & resume_skills\n",
    "skill_score = len(matched_skills) / len(jd_skills) if jd_skills else 0\n",
    "\n",
    "# Display\n",
    "print(\"Job Description Skills:\", jd_skills)\n",
    "print(\"Resume Skills:\", resume_skills)\n",
    "print(\"Matched Skills:\", matched_skills)\n",
    "print(f\"Skill Match Score: {skill_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96a0f5-18dd-4410-b6d5-218ab977bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = calculate_resume_score(resume_text, job_description)\n",
    "print(f\"\\nFinal Resume Score: {final_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27677d-ef1f-40c5-829d-5c91a32089bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b80a37-e4fe-4cb2-8f64-ad0792b27fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Extract top N keywords using TF-IDF\n",
    "def extract_top_n_keywords(text, n=10):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    scores = tfidf_matrix.toarray().flatten()\n",
    "    keywords = sorted(zip(feature_names, scores), key=lambda x: -x[1])[:n]\n",
    "    return set(k for k, _ in keywords)\n",
    "\n",
    "# Compute cosine similarity between two texts\n",
    "def get_similarity_score(text1, text2):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "    return cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "\n",
    "# Main function to compute final score\n",
    "def calculate_resume_score(resume_text, job_text):\n",
    "    # Skill score based on keyword overlap\n",
    "    resume_keywords = extract_top_n_keywords(resume_text)\n",
    "    job_keywords = extract_top_n_keywords(job_text)\n",
    "    if job_keywords:\n",
    "        skill_score = len(resume_keywords & job_keywords) / len(job_keywords)\n",
    "    else:\n",
    "        skill_score = 0.0\n",
    "\n",
    "    # Experience score: simple rule-based logic\n",
    "    experience_score = 1.0 if any(x in resume_text.lower() for x in [\"2 years\", \"3 years\", \"experience\"]) else 0.5\n",
    "\n",
    "    # Education score: basic keyword check\n",
    "    education_score = 1.0 if any(x in resume_text.lower() for x in [\"b.tech\", \"bachelor\", \"graduation\"]) else 0.0\n",
    "\n",
    "    # Weighted final score\n",
    "    final_score = (0.5 * skill_score) + (0.3 * experience_score) + (0.2 * education_score)\n",
    "    return final_score\n",
    "\n",
    "# Usage\n",
    "score = calculate_resume_score(resume_text, job_description)\n",
    "print(f\"\\n Final Resume Score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf1ab7-f575-4898-9ec3-c9652c214f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
